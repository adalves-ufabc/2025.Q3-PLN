{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2025.Q3-PLN/blob/main/2025_Q3_PLN_AULA_14_Notebook_23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2025-Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmK05FgcOzL2"
      },
      "source": [
        "## **API da Groq**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Groq** é uma empresa de tecnologia que desenvolve hardware e software voltados para computação de alto desempenho, particularmente em aplicações de IA e aprendizado de máquina. Fundada por ex-engenheiros da Google, a **Groq** é conhecida por seus chips de processamento (chamados de \"*Tensor Streaming Processor*\" ou *TSP*) que são projetados para acelerar tarefas de IA, como a inferência de modelos de aprendizado profundo."
      ],
      "metadata": {
        "id": "pGqVQ50gypCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para criar uma chave:\n",
        "\n",
        "> https://console.groq.com/keys"
      ],
      "metadata": {
        "id": "lnBY4ssQyaz1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYKEbnlNTVlR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "945bbe4b-f243-4037-c7e4-974fe5e8a579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/135.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title Instalando a biblioteca da API\n",
        "!pip install -q -U groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJvs5RTcbE64",
        "outputId": "59fa5fc1-fc34-4047-96bd-1f1d46a3cdb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.33.0\n"
          ]
        }
      ],
      "source": [
        "#@title Versão da API\n",
        "\n",
        "import groq\n",
        "\n",
        "print(groq.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM5RnKClbPtQ",
        "outputId": "167c8de9-4ed1-4f95-9874-7d7743844bc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "#@title Definindo a chave da API\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "GROQ_API_KEY = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmXsL5yZcKlZ",
        "outputId": "8c023e68-d7a2-4921-e840-9774b4939bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Teste\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "cliente = Groq(api_key = GROQ_API_KEY)\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "    messages = [{\"role\": \"user\", \"content\": \"Qual a capital do Brasil? Responde apenas o nome\"}],\n",
        "    model = \"llama-3.3-70b-versatile\",\n",
        ")"
      ],
      "metadata": {
        "id": "QBU58sBzwcak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACMUndIiyO3b",
        "outputId": "860e66c4-330c-4d09-e2f6-fc385cbb9c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-1fd6ab37-69c8-4887-8fa2-5b578b53630e', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Brasília', role='assistant', executed_tools=None, function_call=None, reasoning=None, tool_calls=None))], created=1761834116, model='llama-3.3-70b-versatile', object='chat.completion', system_fingerprint='fp_7cb24168fa', usage=CompletionUsage(completion_tokens=4, prompt_tokens=46, total_tokens=50, completion_time=0.011231885, prompt_time=0.002143955, queue_time=0.009010976, total_time=0.01337584), usage_breakdown=None, x_groq={'id': 'req_01k8tqy921e75aawf4fahh2rch'}, service_tier='on_demand')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(resposta.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnK6usTpyMTo",
        "outputId": "3a3cc90c-682b-4132-df12-988ee23e2ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brasília\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Lista de Modelos\n",
        "\n",
        "import requests\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "\n",
        "api_key = os.environ.get(\"GROQ_API_KEY\")\n",
        "\n",
        "url = \"https://api.groq.com/openai/v1/models\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "resposta = requests.get(url, headers=headers)"
      ],
      "metadata": {
        "id": "eC4VmnEPy-Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FH-HOWrzReH",
        "outputId": "9d58ea75-5ee0-461e-a8be-ad7d84d4a08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'object': 'list',\n",
              " 'data': [{'id': 'openai/gpt-oss-120b',\n",
              "   'object': 'model',\n",
              "   'created': 1754408224,\n",
              "   'owned_by': 'OpenAI',\n",
              "   'active': True,\n",
              "   'context_window': 131072,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 65536},\n",
              "  {'id': 'groq/compound',\n",
              "   'object': 'model',\n",
              "   'created': 1756949530,\n",
              "   'owned_by': 'Groq',\n",
              "   'active': True,\n",
              "   'context_window': 131072,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 8192},\n",
              "  {'id': 'meta-llama/llama-4-scout-17b-16e-instruct',\n",
              "   'object': 'model',\n",
              "   'created': 1743874824,\n",
              "   'owned_by': 'Meta',\n",
              "   'active': True,\n",
              "   'context_window': 131072,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 8192},\n",
              "  {'id': 'whisper-large-v3-turbo',\n",
              "   'object': 'model',\n",
              "   'created': 1728413088,\n",
              "   'owned_by': 'OpenAI',\n",
              "   'active': True,\n",
              "   'context_window': 448,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 448},\n",
              "  {'id': 'openai/gpt-oss-safeguard-20b',\n",
              "   'object': 'model',\n",
              "   'created': 1761708789,\n",
              "   'owned_by': 'OpenAI',\n",
              "   'active': True,\n",
              "   'context_window': 131072,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 65536},\n",
              "  {'id': 'moonshotai/kimi-k2-instruct',\n",
              "   'object': 'model',\n",
              "   'created': 1752435491,\n",
              "   'owned_by': 'Moonshot AI',\n",
              "   'active': True,\n",
              "   'context_window': 131072,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 16384},\n",
              "  {'id': 'llama-3.3-70b-versatile',\n",
              "   'object': 'model',\n",
              "   'created': 1733447754,\n",
              "   'owned_by': 'Meta',\n",
              "   'active': True,\n",
              "   'context_window': 131072,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 32768},\n",
              "  {'id': 'meta-llama/llama-guard-4-12b',\n",
              "   'object': 'model',\n",
              "   'created': 1746743847,\n",
              "   'owned_by': 'Meta',\n",
              "   'active': True,\n",
              "   'context_window': 131072,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 1024},\n",
              "  {'id': 'llama-3.1-8b-instant',\n",
              "   'object': 'model',\n",
              "   'created': 1693721698,\n",
              "   'owned_by': 'Meta',\n",
              "   'active': True,\n",
              "   'context_window': 131072,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 131072},\n",
              "  {'id': 'playai-tts-arabic',\n",
              "   'object': 'model',\n",
              "   'created': 1740682783,\n",
              "   'owned_by': 'PlayAI',\n",
              "   'active': True,\n",
              "   'context_window': 8192,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 8192},\n",
              "  {'id': 'groq/compound-mini',\n",
              "   'object': 'model',\n",
              "   'created': 1756949707,\n",
              "   'owned_by': 'Groq',\n",
              "   'active': True,\n",
              "   'context_window': 131072,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 8192},\n",
              "  {'id': 'allam-2-7b',\n",
              "   'object': 'model',\n",
              "   'created': 1737672203,\n",
              "   'owned_by': 'SDAIA',\n",
              "   'active': True,\n",
              "   'context_window': 4096,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 4096},\n",
              "  {'id': 'openai/gpt-oss-20b',\n",
              "   'object': 'model',\n",
              "   'created': 1754407957,\n",
              "   'owned_by': 'OpenAI',\n",
              "   'active': True,\n",
              "   'context_window': 131072,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 65536},\n",
              "  {'id': 'whisper-large-v3',\n",
              "   'object': 'model',\n",
              "   'created': 1693721698,\n",
              "   'owned_by': 'OpenAI',\n",
              "   'active': True,\n",
              "   'context_window': 448,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 448},\n",
              "  {'id': 'meta-llama/llama-4-maverick-17b-128e-instruct',\n",
              "   'object': 'model',\n",
              "   'created': 1743877158,\n",
              "   'owned_by': 'Meta',\n",
              "   'active': True,\n",
              "   'context_window': 131072,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 8192},\n",
              "  {'id': 'meta-llama/llama-prompt-guard-2-22m',\n",
              "   'object': 'model',\n",
              "   'created': 1748632101,\n",
              "   'owned_by': 'Meta',\n",
              "   'active': True,\n",
              "   'context_window': 512,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 512},\n",
              "  {'id': 'moonshotai/kimi-k2-instruct-0905',\n",
              "   'object': 'model',\n",
              "   'created': 1757046093,\n",
              "   'owned_by': 'Moonshot AI',\n",
              "   'active': True,\n",
              "   'context_window': 262144,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 16384},\n",
              "  {'id': 'qwen/qwen3-32b',\n",
              "   'object': 'model',\n",
              "   'created': 1748396646,\n",
              "   'owned_by': 'Alibaba Cloud',\n",
              "   'active': True,\n",
              "   'context_window': 131072,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 40960},\n",
              "  {'id': 'meta-llama/llama-prompt-guard-2-86m',\n",
              "   'object': 'model',\n",
              "   'created': 1748632165,\n",
              "   'owned_by': 'Meta',\n",
              "   'active': True,\n",
              "   'context_window': 512,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 512},\n",
              "  {'id': 'playai-tts',\n",
              "   'object': 'model',\n",
              "   'created': 1740682771,\n",
              "   'owned_by': 'PlayAI',\n",
              "   'active': True,\n",
              "   'context_window': 8192,\n",
              "   'public_apps': None,\n",
              "   'max_completion_tokens': 8192}]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados = resposta.json()\n",
        "\n",
        "largura_id = max(len(model['id']) for model in dados['data']) + 2\n",
        "largura_owner = max(len(model['owned_by']) for model in dados['data']) + 2\n",
        "\n",
        "print(f\"{'ID'.ljust(largura_id)} Proprietário\")\n",
        "\n",
        "for modelo in dados['data']:\n",
        "    print(f\"{modelo['id'].ljust(largura_id)} {modelo['owned_by']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4OTVNaN0XEo",
        "outputId": "cf013b2d-f45a-4086-dbaf-f50f9e5ce25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID                                              Proprietário\n",
            "openai/gpt-oss-120b                             OpenAI\n",
            "groq/compound                                   Groq\n",
            "meta-llama/llama-4-scout-17b-16e-instruct       Meta\n",
            "whisper-large-v3-turbo                          OpenAI\n",
            "openai/gpt-oss-safeguard-20b                    OpenAI\n",
            "moonshotai/kimi-k2-instruct                     Moonshot AI\n",
            "llama-3.3-70b-versatile                         Meta\n",
            "meta-llama/llama-guard-4-12b                    Meta\n",
            "llama-3.1-8b-instant                            Meta\n",
            "playai-tts-arabic                               PlayAI\n",
            "groq/compound-mini                              Groq\n",
            "allam-2-7b                                      SDAIA\n",
            "openai/gpt-oss-20b                              OpenAI\n",
            "whisper-large-v3                                OpenAI\n",
            "meta-llama/llama-4-maverick-17b-128e-instruct   Meta\n",
            "meta-llama/llama-prompt-guard-2-22m             Meta\n",
            "moonshotai/kimi-k2-instruct-0905                Moonshot AI\n",
            "qwen/qwen3-32b                                  Alibaba Cloud\n",
            "meta-llama/llama-prompt-guard-2-86m             Meta\n",
            "playai-tts                                      PlayAI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://console.groq.com/docs/quickstart\n",
        "\n",
        "https://github.com/groq/groq-api-cookbook"
      ],
      "metadata": {
        "id": "PhZvR1VSx7js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Integração com o LangChain**"
      ],
      "metadata": {
        "id": "H8uVt3ChbVtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-groq"
      ],
      "metadata": {
        "id": "n3aTfMcFbqbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "modelo = ChatGroq(model=\"llama-3.3-70b-versatile\", api_key = GROQ_API_KEY)"
      ],
      "metadata": {
        "id": "kqtjvemCbxeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "mensagens = [\n",
        "    SystemMessage(content=\"Traduza o seguinte do Inglês para o Português\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "resposta = modelo.invoke(mensagens)"
      ],
      "metadata": {
        "id": "CMLBK8tob10m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTPrtwKBcJMm",
        "outputId": "cb5ca892-1a4f-4a22-d81e-6592afda7137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Olá!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 52, 'total_tokens': 56, 'completion_time': 0.010644197, 'prompt_time': 0.003067849, 'queue_time': 0.039157939, 'total_time': 0.013712046}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_4e7667efac', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--6abd2739-de25-4b75-9a9d-231d1f86a4a6-0', usage_metadata={'input_tokens': 52, 'output_tokens': 4, 'total_tokens': 56})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CGDDUr7zcLWy",
        "outputId": "0bf72611-c646-4459-d73d-d209d6f594c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olá!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ChatPromptTemplate**"
      ],
      "metadata": {
        "id": "hXo-EcS2cQWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"Traduza o seguinte para {idioma}:\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{texto}\")]\n",
        ")\n",
        "\n",
        "prompt = prompt_template.invoke({\"idioma\": \"italiano\", \"texto\": \"hi\"})\n",
        "\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHBakft8f9Vl",
        "outputId": "69631552-bbe6-4922-d259-6b1fdad965c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Traduza o seguinte para italiano:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.to_messages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqn0u8fMgVkB",
        "outputId": "73c67d09-c236-42f0-d6a2-1e3009c8c94f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='Traduza o seguinte para italiano:', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='hi', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# envia o prompt ao modelo\n",
        "resposta = modelo.invoke(prompt)\n",
        "\n",
        "print(resposta.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSbbdOgMd8Bs",
        "outputId": "d650810e-55c9-4cc3-ce7f-bb76276128d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ciao!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain =  prompt_template | modelo\n",
        "\n",
        "resposta = chain.invoke({\"idioma\": \"português\", \"texto\": \"hi\"})"
      ],
      "metadata": {
        "id": "02pE5aUqXaGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSf0ZxSUkYoF",
        "outputId": "d4453473-f348-46a7-b6df-58f9fb280dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Olá!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 47, 'total_tokens': 51, 'completion_time': 0.010631586, 'prompt_time': 0.002181803, 'queue_time': 0.009204071, 'total_time': 0.012813389}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_a7161653a1', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--e6b97b7b-a535-4265-90e7-0e7aecec3e95-0', usage_metadata={'input_tokens': 47, 'output_tokens': 4, 'total_tokens': 51})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kpO8W3PIkaHa",
        "outputId": "5e200558-14eb-4dfb-b64a-d2f501aba233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olá!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encadeando componentes com LCEL**"
      ],
      "metadata": {
        "id": "cV0BuA6dgjHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "VjipoOCkghDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt_template | modelo | parser"
      ],
      "metadata": {
        "id": "DSvspJQbgbFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"idioma\": \"portugues\", \"texto\": \"hi\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3iJp6twogrPE",
        "outputId": "fa9471e2-2318-4745-9024-847b6ef26849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olá!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cadeias**"
      ],
      "metadata": {
        "id": "UFDo_ErJhWIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "dQ8iJz0qjYqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = ChatGroq(model=\"llama-3.3-70b-versatile\", api_key = GROQ_API_KEY)"
      ],
      "metadata": {
        "id": "FSkaLZdVjaN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"Me conte uma piada sobre {assunto}\")\n",
        "chain = prompt | modelo"
      ],
      "metadata": {
        "id": "n6ruRLp3jIoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chain.invoke({\"assunto\": \"papagaio\"})"
      ],
      "metadata": {
        "id": "ubjzAw-3jesT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(resposta.content)"
      ],
      "metadata": {
        "id": "dtN95fuclcvO",
        "outputId": "11f6e76f-b48b-4cfa-f352-e47ad34868fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Um papagaio foi ao médico e disse: \"Doutor, eu estou com um problema. Eu só consigo dizer 'Polly quer bala'!\"\n\nO médico respondeu: \"Não se preocupe, é apenas um problema de réplica!\""
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mais um exemplo:"
      ],
      "metadata": {
        "id": "vGmxLMnazSwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "modelo = ChatGroq(model=\"llama-3.3-70b-versatile\", api_key = GROQ_API_KEY)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Você é um assistente que traduz {idioma_input} para {idioma_output}.\",\n",
        "        ),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | modelo\n",
        "\n",
        "resposta = chain.invoke(\n",
        "    {\n",
        "        \"idioma_input\": \"Inglês\",\n",
        "        \"idioma_output\": \"Português\",\n",
        "        \"input\": \"I love programming.\",\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "aW0B_raRnMhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kPrGvXoynWaj",
        "outputId": "a987e8db-549f-4021-e25e-3cdd82aa3734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Eu amo programação.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxrYnFtSfJam/UfWOJnfdQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}