{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2025.Q3-PLN/blob/main/2025_Q3_PLN_AULA_13_Notebook_22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2025-Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmK05FgcOzL2"
      },
      "source": [
        "## **IntegraÃ§Ã£o da API Cohere com o LangChain**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cYKEbnlNTVlR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e51a63-f955-4f81-f1cd-5ca8d8651bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title Instalando a biblioteca de integraÃ§Ã£o com o LangChain\n",
        "!pip install -qU langchain-cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM5RnKClbPtQ",
        "outputId": "a2362132-c080-485f-9493-b914052dad2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "#@title Definindo a chave da API\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "COHERE_API_KEY = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIm2e-8cFEIC",
        "outputId": "0794ee94-9134-4b27-a197-99146a17b389"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IntegraÃ§Ã£o**"
      ],
      "metadata": {
        "id": "L0xrlQKjfD1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_cohere import ChatCohere\n",
        "\n",
        "#modelo = ChatCohere(model=\"command-a-03-2025\")\n",
        "modelo = ChatCohere(model=\"command-a-03-2025\", cohere_api_key = COHERE_API_KEY)"
      ],
      "metadata": {
        "id": "c2YPEzwcfBl_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "mensagens = [\n",
        "    SystemMessage(content=\"Traduza o seguinte do InglÃªs para o PortuguÃªs\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "resposta = modelo.invoke(mensagens)"
      ],
      "metadata": {
        "id": "usi_NS9mfKYX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XkoPqFQfaTs",
        "outputId": "cb94c5e8-ebb0-42f4-e97a-2c831c8de44f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='OlÃ¡!', additional_kwargs={'id': 'ae09f018-f326-438c-8206-1b86aa7efec4', 'finish_reason': 'COMPLETE', 'content': 'OlÃ¡!', 'token_count': {'input_tokens': 540.0, 'output_tokens': 5.0}}, response_metadata={'id': 'ae09f018-f326-438c-8206-1b86aa7efec4', 'finish_reason': 'COMPLETE', 'content': 'OlÃ¡!', 'token_count': {'input_tokens': 540.0, 'output_tokens': 5.0}}, id='run--037c4684-357a-4121-9e5b-6512d81ad7b5-0', usage_metadata={'input_tokens': 540, 'output_tokens': 5, 'total_tokens': 545})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zAhmZYjlfXL0",
        "outputId": "8bd16c33-5f86-405a-d02b-2f74e0357cd5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'OlÃ¡!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Templates de *prompts***"
      ],
      "metadata": {
        "id": "ss39e8VbgFeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"Traduza o seguinte texto para {idioma}:\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{texto}\")]\n",
        ")\n",
        "\n",
        "prompt = prompt_template.invoke({\"idioma\": \"italiano\", \"texto\": \"hi\"})\n",
        "\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHBakft8f9Vl",
        "outputId": "6bb3420f-a66a-4499-df56-816c0115ac8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Traduza o seguinte texto para italiano:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.to_messages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqn0u8fMgVkB",
        "outputId": "49913c71-1bb9-498d-f992-84f345ab0c89"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='Traduza o seguinte texto para italiano:', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='hi', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# envia o prompt ao modelo\n",
        "resposta = modelo.invoke(prompt)\n",
        "\n",
        "print(resposta.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jXmCGlqYqwX",
        "outputId": "64f05b36-6766-43c1-804a-64bb3dc2b1db"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ciao! Come posso aiutarti oggi?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain =  prompt_template | modelo\n",
        "\n",
        "resposta = chain.invoke({\"idioma\": \"portuguÃªs\", \"texto\": \"hi\"})\n",
        "resposta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02pE5aUqXaGA",
        "outputId": "8649a17e-789d-485b-a84c-def17c38897e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='OlÃ¡!', additional_kwargs={'id': '283fe997-3190-4270-ae4b-cb636816b922', 'finish_reason': 'COMPLETE', 'content': 'OlÃ¡!', 'token_count': {'input_tokens': 538.0, 'output_tokens': 5.0}}, response_metadata={'id': '283fe997-3190-4270-ae4b-cb636816b922', 'finish_reason': 'COMPLETE', 'content': 'OlÃ¡!', 'token_count': {'input_tokens': 538.0, 'output_tokens': 5.0}}, id='run--571726e6-3ccc-44e5-b34a-0e254c31892d-0', usage_metadata={'input_tokens': 538, 'output_tokens': 5, 'total_tokens': 543})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3Ewbwx33BkQw",
        "outputId": "a637a41a-09ff-4113-9863-35883a2f4082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'OlÃ¡!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encadeando componentes com LCEL**"
      ],
      "metadata": {
        "id": "cV0BuA6dgjHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "VjipoOCkghDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt_template | modelo | parser"
      ],
      "metadata": {
        "id": "DSvspJQbgbFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"idioma\": \"portugues\", \"texto\": \"hi\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3iJp6twogrPE",
        "outputId": "ad9ed0c3-e01d-4a71-e656-38b8d4e94e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'OlÃ¡!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cadeias**"
      ],
      "metadata": {
        "id": "UFDo_ErJhWIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_cohere import ChatCohere\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "dQ8iJz0qjYqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatCohere()"
      ],
      "metadata": {
        "id": "FSkaLZdVjaN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"Me conte uma piada sobre {assunto}\")\n",
        "chain = prompt | chat"
      ],
      "metadata": {
        "id": "n6ruRLp3jIoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chain.invoke({\"assunto\": \"papagaio\"})"
      ],
      "metadata": {
        "id": "ubjzAw-3jesT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(resposta.content)"
      ],
      "metadata": {
        "id": "dtN95fuclcvO",
        "outputId": "b1c3549d-504a-46b2-88ed-5caf8dcee8b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Aqui vai uma piada sobre papagaio:\n\nUm homem entra em uma loja de animais e vÃª um papagaio lindo, mas com uma pata enfaixada. Ele pergunta ao dono da loja:\n\nâ€” O que aconteceu com a pata dele?\n\nO dono responde:\n\nâ€” Ah, ele Ã© um papagaio muito inteligente, mas tem um defeito: ele Ã© viciado em cafÃ©. Um dia, ele tentou pegar a cafeteira quente e se queimou. Por isso, a pata estÃ¡ enfaixada.\n\nO homem, intrigado, pergunta:\n\nâ€” E ele ainda fala?\n\nO dono responde:\n\nâ€” Claro! Mas agora, em vez de dizer \"Ã³i, tudo bem?\", ele diz: \"Passa o cafÃ©, por favor!\"\n\nEspero que tenha gostado! ğŸ˜„"
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCK7jS3/hhOIs8/uzV+y7q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}