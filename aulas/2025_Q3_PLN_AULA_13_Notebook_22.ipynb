{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2025.Q3-PLN/blob/main/2025_Q3_PLN_AULA_13_Notebook_22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2025-Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmK05FgcOzL2"
      },
      "source": [
        "## **Integração da API Cohere com o LangChain**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYKEbnlNTVlR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34bc8dcb-4f20-4df7-c9a2-af7d0c6897f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/303.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m297.0/303.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title Instalando a biblioteca de integração com o LangChain\n",
        "!pip install -qU langchain-cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM5RnKClbPtQ",
        "outputId": "529aed74-2350-484e-bd0b-5f404aeacff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "#@title Definindo a chave da API\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Integração**"
      ],
      "metadata": {
        "id": "L0xrlQKjfD1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_cohere import ChatCohere\n",
        "\n",
        "modelo = ChatCohere(model=\"command-a-03-2025\")"
      ],
      "metadata": {
        "id": "c2YPEzwcfBl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "mensagens = [\n",
        "    SystemMessage(content=\"Traduza o seguinte do Inglês para o Português\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "resposta = modelo.invoke(mensagens)"
      ],
      "metadata": {
        "id": "usi_NS9mfKYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XkoPqFQfaTs",
        "outputId": "a43a3a0e-f77e-4113-ffe5-3a292e70e1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Olá!', additional_kwargs={'id': '4d6acac7-5745-45ff-8150-ceb7d9bc06e7', 'finish_reason': 'COMPLETE', 'content': 'Olá!', 'token_count': {'input_tokens': 540.0, 'output_tokens': 5.0}}, response_metadata={'id': '4d6acac7-5745-45ff-8150-ceb7d9bc06e7', 'finish_reason': 'COMPLETE', 'content': 'Olá!', 'token_count': {'input_tokens': 540.0, 'output_tokens': 5.0}}, id='run--b6ef7590-083f-4a6b-8378-8a84dcc8e54a-0', usage_metadata={'input_tokens': 540, 'output_tokens': 5, 'total_tokens': 545})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zAhmZYjlfXL0",
        "outputId": "25643bed-c0cc-439b-e2cb-a84f9cbc24b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olá!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Templates de *prompts***"
      ],
      "metadata": {
        "id": "ss39e8VbgFeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"Traduza o seguinte para {idioma}:\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{texto}\")]\n",
        ")\n",
        "\n",
        "resultado = prompt_template.invoke({\"idioma\": \"italiano\", \"texto\": \"hi\"})\n",
        "\n",
        "resultado"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHBakft8f9Vl",
        "outputId": "b7ff06d5-845d-45ca-a505-653c37743e18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Traduza o seguinte para italiano:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultado.to_messages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqn0u8fMgVkB",
        "outputId": "c41ffde7-0f06-4865-c42b-906e041807b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='Traduza o seguinte para italiano:', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='hi', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain =  prompt_template | modelo\n",
        "\n",
        "chain.invoke({\"idioma\": \"português\", \"texto\": \"hi\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02pE5aUqXaGA",
        "outputId": "c0800edd-973f-4d9f-bd0e-c37c041c18e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Olá!', additional_kwargs={'id': '90942dbf-eac3-43e0-b88e-d185c83f5ed8', 'finish_reason': 'COMPLETE', 'content': 'Olá!', 'token_count': {'input_tokens': 537.0, 'output_tokens': 5.0}}, response_metadata={'id': '90942dbf-eac3-43e0-b88e-d185c83f5ed8', 'finish_reason': 'COMPLETE', 'content': 'Olá!', 'token_count': {'input_tokens': 537.0, 'output_tokens': 5.0}}, id='run--96cf5675-71a7-48f2-8755-1a9bf2e06c92-0', usage_metadata={'input_tokens': 537, 'output_tokens': 5, 'total_tokens': 542})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encadeando componentes com LCEL**"
      ],
      "metadata": {
        "id": "cV0BuA6dgjHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "VjipoOCkghDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt_template | modelo | parser"
      ],
      "metadata": {
        "id": "DSvspJQbgbFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"idioma\": \"portugues\", \"texto\": \"hi\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3iJp6twogrPE",
        "outputId": "bd5bf4ac-523b-4bc9-c45b-c299edb699a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olá!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cadeias**"
      ],
      "metadata": {
        "id": "UFDo_ErJhWIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_cohere import ChatCohere\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "dQ8iJz0qjYqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatCohere()"
      ],
      "metadata": {
        "id": "FSkaLZdVjaN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"Me conte uma piada sobre {assunto}\")\n",
        "chain = prompt | chat"
      ],
      "metadata": {
        "id": "n6ruRLp3jIoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chain.invoke({\"assunto\": \"papagaio\"})"
      ],
      "metadata": {
        "id": "ubjzAw-3jesT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(resposta.content)"
      ],
      "metadata": {
        "id": "dtN95fuclcvO",
        "outputId": "1e779d59-75a2-4795-d036-fdf5133d8cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Aqui vai uma piada sobre papagaio:\n\nUm homem entra em uma loja de animais e vê um papagaio lindo, mas com uma pata enfaixada. Ele pergunta ao dono da loja:\n\n— O que aconteceu com a pata dele?\n\nO dono responde:\n\n— Ah, ele é um papagaio muito inteligente, mas tem um defeito: ele é viciado em café. Um dia, ele tentou pegar a chaleira do fogão e se queimou a pata.\n\nO homem fica impressionado e pergunta:\n\n— E como ele está agora?\n\nO dono responde:\n\n— Ah, ele está bem, mas agora só toma café **de-cafeinado**!\n\n(Entendeu? \"De-cafeinado\" soa como \"de cá feiado\", que seria \"daqui a uma semana\" em português, mas é só uma brincadeira com as palavras!)\n\nEspero que tenha gostado! 😄"
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuFyWxVToDDE1A+cMzadLH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}