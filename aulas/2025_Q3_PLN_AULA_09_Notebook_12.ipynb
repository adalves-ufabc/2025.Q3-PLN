{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2025.Q3-PLN/blob/main/2025_Q3_PLN_AULA_09_Notebook_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Processamento de Linguagem Natural [2025-Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ],
      "metadata": {
        "id": "g1W8SH-MUgZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introdução à API da OpenAI**\n",
        "---\n"
      ],
      "metadata": {
        "id": "7Kta7e1AUeub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFIowMuI69Lv",
        "outputId": "e0b7bbca-4ebf-4899-e1cf-22f2c9bf50aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "#@title Versão do Python no Google Colab\n",
        "\n",
        "import sys\n",
        "\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwdwRDIwC5Me"
      },
      "source": [
        "## **Configuração da API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjLmc6Yr1a2B",
        "outputId": "8ad6b299-2b26-4ed4-e030-aeffa79eaa03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "#@title Instalando a biblioteca da API da OpenAI\n",
        "\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbFq4KS1fa4T",
        "outputId": "9ef14fd3-412d-4184-c0fc-3bfb17db262b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.109.1\n"
          ]
        }
      ],
      "source": [
        "45#@title Versão da API da OpenAI\n",
        "import openai\n",
        "\n",
        "print(openai.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKCJiyiP-UaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328b6e5d-a39b-44f4-f256-b402ebfc9dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "#@title Definindo a chave da API\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDMK2_pJSD_q"
      },
      "source": [
        "## **Exemplos**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baQkdS4qNBBX"
      },
      "outputs": [],
      "source": [
        "# função para remover quaisquer caracteres de quebra de linha\n",
        "\n",
        "import re\n",
        "\n",
        "def formatar_saida(saida):\n",
        "   return re.sub(r'^\\s+', '', saida)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57sz9IOtSKaJ"
      },
      "source": [
        "**Dados textuais**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_2zVcpTSlz3"
      },
      "outputs": [],
      "source": [
        "#@title Continuação do Texto (*Text Completion*)\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = [{\"role\": \"user\", \"content\": \"O Brasil é famoso\"}],\n",
        "    max_tokens = 30,\n",
        "    temperature = 0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(resposta.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKf3dLBVuch2",
        "outputId": "0739f559-8605-4218-fa6e-fec17b8e1198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O Brasil é famoso por diversas razões, incluindo sua rica cultura, biodiversidade, paisagens deslumbrantes e eventos icônicos. Aqui estão alguns dos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyh8g4G1vqg2"
      },
      "outputs": [],
      "source": [
        "#@title Continuação do Texto (*Text Completion*) - Gerando n respostas\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo-0125\",\n",
        "    messages = [{\"role\": \"user\", \"content\": \"O Brasil é famoso\"}],\n",
        "    max_tokens = 15,\n",
        "    n = 3,\n",
        "    temperature = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for resp in resposta.choices:\n",
        "  print(formatar_saida(resp.message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maSXm7Fwuj7o",
        "outputId": "427afc67-f791-4613-e159-8e540b43e28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "por muitas coisas, como suas praias paradisíacas\n",
            "por suas praias paradisíacas, festas animadas como\n",
            "por suas belas praias, diversidade cultural, festas anim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoBDX_IQwteX"
      },
      "outputs": [],
      "source": [
        "#@title Correção gramatical\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Você receberá instruções e sua tarefa é corrigir para o Português\"},\n",
        "               {\"role\": \"user\", \"content\": \"o mecado estav fexado.\"}]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NArpgwhrv7N9",
        "outputId": "9710e923-4bbd-424f-fd6a-2c45fad1ef2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O mercado estava fechado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUdq_Z-Bxx-K"
      },
      "outputs": [],
      "source": [
        "#@title Classificação de Textos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Classifique o texto da seguinte mensagem como 'spam' ou 'não spam\"},\n",
        "               {\"role\": \"user\", \"content\": \"Você ganhou um milhão de reais na loteria. Clique neste link\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9nRdlpWwbnz",
        "outputId": "9ee87a20-e90a-4a61-ed51-7f7b7e0f6b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJFY-0H_28C1"
      },
      "outputs": [],
      "source": [
        "#@title Análise de Sentimentos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Analise apenas se o sentimento de uma frase é positivo, neutro ou negativo\"},\n",
        "               {\"role\": \"user\", \"content\": \"Frase: Eu odeio acordar cedo para ir trabalhar, mas adoro o meu trabalho. Sentimento=\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjJs6qjkwzwS",
        "outputId": "97da56e0-2e13-4608-b515-0672df1962f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentimento: neutro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRC-Uplp35xX"
      },
      "outputs": [],
      "source": [
        "#@title Detecção de Emoções\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Identifique apenas as emoções nos seguintes tweets\"},\n",
        "               {\"role\": \"user\", \"content\": \"\"\"1. \\\"Eu não suporto lição de casa\\\"\\n\n",
        "     2. \\\"Isso é péssimo. Estou entediado 😠\\\"\\n\n",
        "     3. \\\"Mal posso esperar pelo dia das bruxas!!!\\\"\\n\n",
        "     4. \\\"Meu gato é adorável ❤️❤️\\\"\\n\n",
        "     5. \\\"Eu odeio chocolate\\\"\\n\"\"\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEw-mnZp0yO4",
        "outputId": "d4f67dc2-075e-405a-e352-a58f72273788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Raiva\n",
            "2. Tédio\n",
            "3. Alegria\n",
            "4. Amor\n",
            "5. Ódio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extração de Informação\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "  model = \"gpt-3.5-turbo-0125\",\n",
        "  messages = [\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Você receberá dados não estruturados e sua tarefa é analisá-los no formato CSV.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"O Brasil é um país de dimensões continentais localizado na América do Sul, com capital em Brasília.\n",
        "                    Santos Dumont foi um brasileiro reconhecido no mundo inteiro. O Brasil é o país do futebol\"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.7,\n",
        "  max_tokens = 64\n",
        ")"
      ],
      "metadata": {
        "id": "6KTgXOjV5ZmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YzSxct-6vm8",
        "outputId": "9b31a0fe-b41b-41ae-8e77-8470c01a0a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "País,Capital\n",
            "Brasil,Brasília\n",
            "Brasil,Santos Dumont\n",
            "Brasil,Futebol\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9rsmdsw6v8X"
      },
      "outputs": [],
      "source": [
        "#@title Extração de Palavras-chave\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Extraia 5 palavras-chave do seguinte texto\"},\n",
        "               {\"role\": \"user\", \"content\": \"\"\"O Brasil é um país de dimensões continentais\n",
        "               localizado na América do Sul, com capital em Brasília. Santos Dumont foi\n",
        "               um brasileiro reconhecido no mundo inteiro. O Brasil é o país do futebol\"\"\"}],\n",
        "   temperature = 0.5,\n",
        "   max_tokens = 64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8odWS_R3Clj",
        "outputId": "5ba162b1-eb43-4068-fbbe-cd04c55ae6f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brasil, dimensões continentais, América do Sul, Santos Dumont, futebol.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrxMdIyZ-I7Q"
      },
      "outputs": [],
      "source": [
        "#@title Tradução de Textos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Você receberá uma frase em português e sua tarefa é traduzi-la para o inglês\"},\n",
        "               {\"role\": \"user\", \"content\": \"Que dia é hoje?\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 30\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkf2-AkH32TN",
        "outputId": "762b6315-fc1f-44fc-8925-50e33367eb30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What day is today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx4g8OjiBmHl"
      },
      "outputs": [],
      "source": [
        "#@title Sumarização de Textos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Você receberá um texto e sua tarefa é resumir o texto em poucas palavras\"},\n",
        "               {\"role\": \"user\", \"content\": \"\"\"Alan Turing foi um matemático e criptógrafo inglês\n",
        "               considerado atualmente como o pai da computação, uma vez que, por meio de suas ideias,\n",
        "               foi possível desenvolver o que chamamos hoje de computador.\"\"\"}],\n",
        "   temperature = 0.5,\n",
        "   max_tokens = 100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X9QjpHc4eGe",
        "outputId": "971edb7e-e818-47af-c87c-975c0a418914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alan Turing: pai da computação, matemático e criptógrafo inglês.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgLvo9-qEHOa",
        "outputId": "7c94ff75-b94a-4f8f-a0eb-fb0b86be1e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qual o seu nome?\n",
            "Não preciso de um nome, pois sou apenas um programa de computador aqui para responder suas perguntas. O que você quer, afinal?\n",
            "sair\n",
            "Ótimo, então vá embora. Não perca mais tempo aqui.\n"
          ]
        }
      ],
      "source": [
        "#@title Chat \"rude\"\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "mensagens = [{'role': 'system', 'content': 'Você é um assistente que responde de maneira rude.'}]\n",
        "mensagem = ''\n",
        "\n",
        "while (mensagem != 'sair'):\n",
        "    mensagem = input()\n",
        "    mensagens.append({'role': 'user', 'content': mensagem})\n",
        "\n",
        "    resposta = cliente.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo-0125\",\n",
        "        messages = mensagens\n",
        "    )\n",
        "\n",
        "    saida = formatar_saida(resposta.choices[0].message.content)\n",
        "\n",
        "    mensagens.append({'role': 'assistant', 'content': saida})\n",
        "    print(saida)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym_4y7ZQSTQO"
      },
      "source": [
        "**Geração de Código**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3dlMUeYK4TV"
      },
      "outputs": [],
      "source": [
        "#@title Geração de código em Python\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "mensagem = (\n",
        "    \"Escreva um programa em Python que leia um número inteiro e \"\n",
        "    \"imprima 'par' se o número for par ou 'ímpar' se for ímpar.\"\n",
        ")\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [\n",
        "      {\"role\": \"system\", \"content\": \"Você é um especialista em programação Python.\"},\n",
        "      {\"role\": \"user\", \"content\": mensagem}\n",
        "   ],\n",
        "   temperature = 0.7,\n",
        "   max_tokens = 100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umonx4goe7B_",
        "outputId": "83ac7e47-eac4-4777-e272-3836be87fa0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claro! Aqui está um exemplo de programa em Python que faz exatamente isso:\n",
            "\n",
            "```python\n",
            "numero = int(input(\"Digite um número inteiro: \"))\n",
            "\n",
            "if numero % 2 == 0:\n",
            "    print(\"par\")\n",
            "else:\n",
            "    print(\"ímpar\")\n",
            "```\n",
            "\n",
            "Você pode copiar e colar esse código em um arquivo Python e executá-lo para testar. Ele solicitará que você insira um número inteiro e, em seguida, imprimir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OScTyXz8Ucrq"
      },
      "outputs": [],
      "source": [
        "#@title SQL\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "mensagem = (\n",
        "    \"Crie uma instrução em MySQL para localizar todos os usuários que\"\n",
        "     \"moram em Santo André e possuem mais de 70 anos. Retorne apenas o código em SQL. \"\n",
        ")\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [\n",
        "      {\"role\": \"system\", \"content\": \"Você é um especialista em SQL.\"},\n",
        "      {\"role\": \"user\", \"content\": mensagem}\n",
        "   ],\n",
        "   temperature = 0.7,\n",
        "   max_tokens = 60\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc-Ymh2kffTV",
        "outputId": "da8ef210-f713-44bd-bede-557a237d5998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```sql\n",
            "SELECT *\n",
            "FROM usuarios\n",
            "WHERE cidade = 'Santo André' AND idade > 70;\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvHGuFVBSUWn"
      },
      "source": [
        "**Aplicações**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltzdVyNV4HOU"
      },
      "outputs": [],
      "source": [
        "#@title Gerador de Comandos Shell\n",
        "\n",
        "from openai import OpenAI\n",
        "import subprocess\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "def gerador_comando_shell(texto):\n",
        "\n",
        "   mensagem = f\"Escreva um comando shell que faça o seguinte: {texto}\"\n",
        "\n",
        "   resposta = cliente.chat.completions.create(\n",
        "       model = \"gpt-3.5-turbo-0125\",\n",
        "       messages = [{\"role\": \"system\", \"content\": \"Você é um especialista em comandos shell\"},\n",
        "                   {\"role\": \"user\", \"content\": mensagem}],\n",
        "       temperature = 0.5,\n",
        "       max_tokens = 60\n",
        "   )\n",
        "\n",
        "   return formatar_saida(resposta.choices[0].message.content)\n",
        "\n",
        "def executar_comando_shell(comando):\n",
        "   try:\n",
        "     resultado = subprocess.run(comando, shell=True, check=True)\n",
        "     print(resultado)\n",
        "   except subprocess.CalledProcessError as e:\n",
        "     print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfQ9KQRV47YC",
        "outputId": "c26faf80-07c6-4a10-be51-83bb3c399435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claro! Você pode usar o comando `mkdir` para criar uma pasta com o nome \"temp\". Aqui está o comando:\n",
            "\n",
            "```bash\n",
            "mkdir temp\n",
            "``` \n",
            "\n",
            "Este comando irá criar uma pasta chamada \"temp\" no diretório atual.\n",
            "Command 'Claro! Você pode usar o comando `mkdir` para criar uma pasta com o nome \"temp\". Aqui está o comando:\n",
            "\n",
            "```bash\n",
            "mkdir temp\n",
            "``` \n",
            "\n",
            "Este comando irá criar uma pasta chamada \"temp\" no diretório atual.' returned non-zero exit status 127.\n"
          ]
        }
      ],
      "source": [
        "# trecho de código para criar uma pasta com o nome temp\n",
        "\n",
        "comando = gerador_comando_shell(\"Crie uma pasta com o nome temp\")\n",
        "print(comando)\n",
        "executar_comando_shell(comando)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn1wbCFU6QUZ",
        "outputId": "0a395a71-b7ab-42d3-908b-9b907828b446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command 'Para apagar a pasta com o nome \"temp\", você pode usar o comando `rm -r temp`. Este comando irá excluir a pasta \"temp\" e todo o seu conteúdo de forma recursiva. Certifique-se de estar no diretório correto antes de executar este comando' returned non-zero exit status 127.\n"
          ]
        }
      ],
      "source": [
        "# trecho de código para apagar uma pasta com o nome temp\n",
        "\n",
        "comando = gerador_comando_shell('apague a pasta com o nome temp')\n",
        "executar_comando_shell(comando)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkh1jl1R79dE"
      },
      "outputs": [],
      "source": [
        "#@title Gerador de Conjuntos de Dados\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "mensagem_sistema = 'Você é um assistente que entende de Ciência de Dados.'\n",
        "\n",
        "mensagem_usuario = \"\"\"\n",
        "   Crie um pequeno conjunto de dados sobre o total de vendas no último ano.\n",
        "   O formato do conjunto de dados deve ser um dataframe com 12 linhas e 2 colunas.\n",
        "   As colunas devem ser chamadas de \"mes\" e \"total_vendas\".\n",
        "   A coluna \"mes\" deve conter as formas abreviadas dos nomes dos meses de \"Jan\" a \"Dez\".\n",
        "   A coluna \"total_vendas\" deve conter valores numéricos aleatórios retirados de um\n",
        "   distribuição normal com média 100000 e desvio padrão 5000.\n",
        "   Forneça o código Python para gerar o conjunto de dados e, em seguida, forneça a saída\n",
        "    no formato de uma tabela.\n",
        "\"\"\"\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo\",\n",
        "   messages = [{\"role\": \"system\", \"content\": mensagem_sistema},\n",
        "               {\"role\": \"user\", \"content\": mensagem_usuario}]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIwiGSTg8QWV",
        "outputId": "e3cca7ad-a26d-4914-ad40-e05707f14e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aqui está o código Python para gerar o conjunto de dados e a saída em formato de tabela:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "\n",
            "# Criando o conjunto de dados\n",
            "meses = [\"Jan\", \"Fev\", \"Mar\", \"Abr\", \"Mai\", \"Jun\", \"Jul\", \"Ago\", \"Set\", \"Out\", \"Nov\", \"Dez\"]\n",
            "total_vendas = np.random.normal(100000, 5000, 12)\n",
            "\n",
            "data = {\n",
            "    \"mes\": meses,\n",
            "    \"total_vendas\": total_vendas\n",
            "}\n",
            "\n",
            "df = pd.DataFrame(data)\n",
            "\n",
            "# Exibindo o conjunto de dados em formato de tabela\n",
            "print(df)\n",
            "```\n",
            "\n",
            "Saída do conjunto de dados em formato de tabela:\n",
            "\n",
            "```\n",
            "    mes    total_vendas\n",
            "0   Jan    98866.395641\n",
            "1   Fev   102568.079104\n",
            "2   Mar   101764.780843\n",
            "3   Abr    98436.707181\n",
            "4   Mai    99455.393352\n",
            "5   Jun    99437.501874\n",
            "6   Jul   100009.352908\n",
            "7   Ago    99600.231724\n",
            "8   Set   103634.287184\n",
            "9   Out    99634.066355\n",
            "10  Nov   101345.453846\n",
            "11  Dez    96619.739903\n",
            "``` \n",
            "\n",
            "Este é um conjunto de dados fictício e os valores de vendas são gerados aleatoriamente usando uma distribuição normal com média de 100000 e desvio padrão de 5000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg5e39wPA3yU",
        "outputId": "c442b0d0-6071-4ba3-e2d0-ba738022af0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    mes   total_vendas\n",
            "0   Jan  107272.920583\n",
            "1   Fev   95710.770321\n",
            "2   Mar   89926.790366\n",
            "3   Abr   97353.753804\n",
            "4   Mai   98580.419847\n",
            "5   Jun   95174.889052\n",
            "6   Jul  100483.774294\n",
            "7   Ago   90394.758696\n",
            "8   Set   97909.761955\n",
            "9   Out  103615.069726\n",
            "10  Nov  103902.347458\n",
            "11  Dez  102186.877579\n"
          ]
        }
      ],
      "source": [
        "#@title Teste do código gerado\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Criando o conjunto de dados\n",
        "meses = [\"Jan\", \"Fev\", \"Mar\", \"Abr\", \"Mai\", \"Jun\", \"Jul\", \"Ago\", \"Set\", \"Out\", \"Nov\", \"Dez\"]\n",
        "total_vendas = np.random.normal(100000, 5000, 12)\n",
        "\n",
        "data = {\n",
        "    \"mes\": meses,\n",
        "    \"total_vendas\": total_vendas\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Exibindo o conjunto de dados em formato de tabela\n",
        "print(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbAZtAiNHDSZgnlZeuRssa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}