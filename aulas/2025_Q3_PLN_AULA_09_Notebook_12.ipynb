{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2025.Q3-PLN/blob/main/2025_Q3_PLN_AULA_09_Notebook_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Processamento de Linguagem Natural [2025-Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ],
      "metadata": {
        "id": "g1W8SH-MUgZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introdu√ß√£o √† API da OpenAI**\n",
        "---\n"
      ],
      "metadata": {
        "id": "7Kta7e1AUeub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFIowMuI69Lv",
        "outputId": "e0b7bbca-4ebf-4899-e1cf-22f2c9bf50aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "#@title Vers√£o do Python no Google Colab\n",
        "\n",
        "import sys\n",
        "\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwdwRDIwC5Me"
      },
      "source": [
        "## **Configura√ß√£o da API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjLmc6Yr1a2B",
        "outputId": "8ad6b299-2b26-4ed4-e030-aeffa79eaa03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "#@title Instalando a biblioteca da API da OpenAI\n",
        "\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbFq4KS1fa4T",
        "outputId": "9ef14fd3-412d-4184-c0fc-3bfb17db262b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.109.1\n"
          ]
        }
      ],
      "source": [
        "45#@title Vers√£o da API da OpenAI\n",
        "import openai\n",
        "\n",
        "print(openai.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKCJiyiP-UaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328b6e5d-a39b-44f4-f256-b402ebfc9dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ],
      "source": [
        "#@title Definindo a chave da API\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDMK2_pJSD_q"
      },
      "source": [
        "## **Exemplos**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baQkdS4qNBBX"
      },
      "outputs": [],
      "source": [
        "# fun√ß√£o para remover quaisquer caracteres de quebra de linha\n",
        "\n",
        "import re\n",
        "\n",
        "def formatar_saida(saida):\n",
        "   return re.sub(r'^\\s+', '', saida)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57sz9IOtSKaJ"
      },
      "source": [
        "**Dados textuais**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_2zVcpTSlz3"
      },
      "outputs": [],
      "source": [
        "#@title Continua√ß√£o do Texto (*Text Completion*)\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = [{\"role\": \"user\", \"content\": \"O Brasil √© famoso\"}],\n",
        "    max_tokens = 30,\n",
        "    temperature = 0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(resposta.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKf3dLBVuch2",
        "outputId": "0739f559-8605-4218-fa6e-fec17b8e1198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O Brasil √© famoso por diversas raz√µes, incluindo sua rica cultura, biodiversidade, paisagens deslumbrantes e eventos ic√¥nicos. Aqui est√£o alguns dos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyh8g4G1vqg2"
      },
      "outputs": [],
      "source": [
        "#@title Continua√ß√£o do Texto (*Text Completion*) - Gerando n respostas\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo-0125\",\n",
        "    messages = [{\"role\": \"user\", \"content\": \"O Brasil √© famoso\"}],\n",
        "    max_tokens = 15,\n",
        "    n = 3,\n",
        "    temperature = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for resp in resposta.choices:\n",
        "  print(formatar_saida(resp.message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maSXm7Fwuj7o",
        "outputId": "427afc67-f791-4613-e159-8e540b43e28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "por muitas coisas, como suas praias paradis√≠acas\n",
            "por suas praias paradis√≠acas, festas animadas como\n",
            "por suas belas praias, diversidade cultural, festas anim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoBDX_IQwteX"
      },
      "outputs": [],
      "source": [
        "#@title Corre√ß√£o gramatical\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Voc√™ receber√° instru√ß√µes e sua tarefa √© corrigir para o Portugu√™s\"},\n",
        "               {\"role\": \"user\", \"content\": \"o mecado estav fexado.\"}]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NArpgwhrv7N9",
        "outputId": "9710e923-4bbd-424f-fd6a-2c45fad1ef2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O mercado estava fechado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUdq_Z-Bxx-K"
      },
      "outputs": [],
      "source": [
        "#@title Classifica√ß√£o de Textos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Classifique o texto da seguinte mensagem como 'spam' ou 'n√£o spam\"},\n",
        "               {\"role\": \"user\", \"content\": \"Voc√™ ganhou um milh√£o de reais na loteria. Clique neste link\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9nRdlpWwbnz",
        "outputId": "9ee87a20-e90a-4a61-ed51-7f7b7e0f6b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJFY-0H_28C1"
      },
      "outputs": [],
      "source": [
        "#@title An√°lise de Sentimentos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Analise apenas se o sentimento de uma frase √© positivo, neutro ou negativo\"},\n",
        "               {\"role\": \"user\", \"content\": \"Frase: Eu odeio acordar cedo para ir trabalhar, mas adoro o meu trabalho. Sentimento=\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjJs6qjkwzwS",
        "outputId": "97da56e0-2e13-4608-b515-0672df1962f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentimento: neutro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRC-Uplp35xX"
      },
      "outputs": [],
      "source": [
        "#@title Detec√ß√£o de Emo√ß√µes\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Identifique apenas as emo√ß√µes nos seguintes tweets\"},\n",
        "               {\"role\": \"user\", \"content\": \"\"\"1. \\\"Eu n√£o suporto li√ß√£o de casa\\\"\\n\n",
        "     2. \\\"Isso √© p√©ssimo. Estou entediado üò†\\\"\\n\n",
        "     3. \\\"Mal posso esperar pelo dia das bruxas!!!\\\"\\n\n",
        "     4. \\\"Meu gato √© ador√°vel ‚ù§Ô∏è‚ù§Ô∏è\\\"\\n\n",
        "     5. \\\"Eu odeio chocolate\\\"\\n\"\"\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEw-mnZp0yO4",
        "outputId": "d4f67dc2-075e-405a-e352-a58f72273788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Raiva\n",
            "2. T√©dio\n",
            "3. Alegria\n",
            "4. Amor\n",
            "5. √ìdio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extra√ß√£o de Informa√ß√£o\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "  model = \"gpt-3.5-turbo-0125\",\n",
        "  messages = [\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Voc√™ receber√° dados n√£o estruturados e sua tarefa √© analis√°-los no formato CSV.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"O Brasil √© um pa√≠s de dimens√µes continentais localizado na Am√©rica do Sul, com capital em Bras√≠lia.\n",
        "                    Santos Dumont foi um brasileiro reconhecido no mundo inteiro. O Brasil √© o pa√≠s do futebol\"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.7,\n",
        "  max_tokens = 64\n",
        ")"
      ],
      "metadata": {
        "id": "6KTgXOjV5ZmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YzSxct-6vm8",
        "outputId": "9b31a0fe-b41b-41ae-8e77-8470c01a0a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pa√≠s,Capital\n",
            "Brasil,Bras√≠lia\n",
            "Brasil,Santos Dumont\n",
            "Brasil,Futebol\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9rsmdsw6v8X"
      },
      "outputs": [],
      "source": [
        "#@title Extra√ß√£o de Palavras-chave\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Extraia 5 palavras-chave do seguinte texto\"},\n",
        "               {\"role\": \"user\", \"content\": \"\"\"O Brasil √© um pa√≠s de dimens√µes continentais\n",
        "               localizado na Am√©rica do Sul, com capital em Bras√≠lia. Santos Dumont foi\n",
        "               um brasileiro reconhecido no mundo inteiro. O Brasil √© o pa√≠s do futebol\"\"\"}],\n",
        "   temperature = 0.5,\n",
        "   max_tokens = 64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8odWS_R3Clj",
        "outputId": "5ba162b1-eb43-4068-fbbe-cd04c55ae6f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brasil, dimens√µes continentais, Am√©rica do Sul, Santos Dumont, futebol.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrxMdIyZ-I7Q"
      },
      "outputs": [],
      "source": [
        "#@title Tradu√ß√£o de Textos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Voc√™ receber√° uma frase em portugu√™s e sua tarefa √© traduzi-la para o ingl√™s\"},\n",
        "               {\"role\": \"user\", \"content\": \"Que dia √© hoje?\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 30\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkf2-AkH32TN",
        "outputId": "762b6315-fc1f-44fc-8925-50e33367eb30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What day is today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx4g8OjiBmHl"
      },
      "outputs": [],
      "source": [
        "#@title Sumariza√ß√£o de Textos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Voc√™ receber√° um texto e sua tarefa √© resumir o texto em poucas palavras\"},\n",
        "               {\"role\": \"user\", \"content\": \"\"\"Alan Turing foi um matem√°tico e cript√≥grafo ingl√™s\n",
        "               considerado atualmente como o pai da computa√ß√£o, uma vez que, por meio de suas ideias,\n",
        "               foi poss√≠vel desenvolver o que chamamos hoje de computador.\"\"\"}],\n",
        "   temperature = 0.5,\n",
        "   max_tokens = 100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X9QjpHc4eGe",
        "outputId": "971edb7e-e818-47af-c87c-975c0a418914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alan Turing: pai da computa√ß√£o, matem√°tico e cript√≥grafo ingl√™s.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgLvo9-qEHOa",
        "outputId": "7c94ff75-b94a-4f8f-a0eb-fb0b86be1e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qual o seu nome?\n",
            "N√£o preciso de um nome, pois sou apenas um programa de computador aqui para responder suas perguntas. O que voc√™ quer, afinal?\n",
            "sair\n",
            "√ìtimo, ent√£o v√° embora. N√£o perca mais tempo aqui.\n"
          ]
        }
      ],
      "source": [
        "#@title Chat \"rude\"\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "mensagens = [{'role': 'system', 'content': 'Voc√™ √© um assistente que responde de maneira rude.'}]\n",
        "mensagem = ''\n",
        "\n",
        "while (mensagem != 'sair'):\n",
        "    mensagem = input()\n",
        "    mensagens.append({'role': 'user', 'content': mensagem})\n",
        "\n",
        "    resposta = cliente.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo-0125\",\n",
        "        messages = mensagens\n",
        "    )\n",
        "\n",
        "    saida = formatar_saida(resposta.choices[0].message.content)\n",
        "\n",
        "    mensagens.append({'role': 'assistant', 'content': saida})\n",
        "    print(saida)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym_4y7ZQSTQO"
      },
      "source": [
        "**Gera√ß√£o de C√≥digo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3dlMUeYK4TV"
      },
      "outputs": [],
      "source": [
        "#@title Gera√ß√£o de c√≥digo em Python\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "mensagem = (\n",
        "    \"Escreva um programa em Python que leia um n√∫mero inteiro e \"\n",
        "    \"imprima 'par' se o n√∫mero for par ou '√≠mpar' se for √≠mpar.\"\n",
        ")\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [\n",
        "      {\"role\": \"system\", \"content\": \"Voc√™ √© um especialista em programa√ß√£o Python.\"},\n",
        "      {\"role\": \"user\", \"content\": mensagem}\n",
        "   ],\n",
        "   temperature = 0.7,\n",
        "   max_tokens = 100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umonx4goe7B_",
        "outputId": "83ac7e47-eac4-4777-e272-3836be87fa0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claro! Aqui est√° um exemplo de programa em Python que faz exatamente isso:\n",
            "\n",
            "```python\n",
            "numero = int(input(\"Digite um n√∫mero inteiro: \"))\n",
            "\n",
            "if numero % 2 == 0:\n",
            "    print(\"par\")\n",
            "else:\n",
            "    print(\"√≠mpar\")\n",
            "```\n",
            "\n",
            "Voc√™ pode copiar e colar esse c√≥digo em um arquivo Python e execut√°-lo para testar. Ele solicitar√° que voc√™ insira um n√∫mero inteiro e, em seguida, imprimir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OScTyXz8Ucrq"
      },
      "outputs": [],
      "source": [
        "#@title SQL\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "mensagem = (\n",
        "    \"Crie uma instru√ß√£o em MySQL para localizar todos os usu√°rios que\"\n",
        "     \"moram em Santo Andr√© e possuem mais de 70 anos. Retorne apenas o c√≥digo em SQL. \"\n",
        ")\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [\n",
        "      {\"role\": \"system\", \"content\": \"Voc√™ √© um especialista em SQL.\"},\n",
        "      {\"role\": \"user\", \"content\": mensagem}\n",
        "   ],\n",
        "   temperature = 0.7,\n",
        "   max_tokens = 60\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc-Ymh2kffTV",
        "outputId": "da8ef210-f713-44bd-bede-557a237d5998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```sql\n",
            "SELECT *\n",
            "FROM usuarios\n",
            "WHERE cidade = 'Santo Andr√©' AND idade > 70;\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvHGuFVBSUWn"
      },
      "source": [
        "**Aplica√ß√µes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltzdVyNV4HOU"
      },
      "outputs": [],
      "source": [
        "#@title Gerador de Comandos Shell\n",
        "\n",
        "from openai import OpenAI\n",
        "import subprocess\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "def gerador_comando_shell(texto):\n",
        "\n",
        "   mensagem = f\"Escreva um comando shell que fa√ßa o seguinte: {texto}\"\n",
        "\n",
        "   resposta = cliente.chat.completions.create(\n",
        "       model = \"gpt-3.5-turbo-0125\",\n",
        "       messages = [{\"role\": \"system\", \"content\": \"Voc√™ √© um especialista em comandos shell\"},\n",
        "                   {\"role\": \"user\", \"content\": mensagem}],\n",
        "       temperature = 0.5,\n",
        "       max_tokens = 60\n",
        "   )\n",
        "\n",
        "   return formatar_saida(resposta.choices[0].message.content)\n",
        "\n",
        "def executar_comando_shell(comando):\n",
        "   try:\n",
        "     resultado = subprocess.run(comando, shell=True, check=True)\n",
        "     print(resultado)\n",
        "   except subprocess.CalledProcessError as e:\n",
        "     print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfQ9KQRV47YC",
        "outputId": "c26faf80-07c6-4a10-be51-83bb3c399435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claro! Voc√™ pode usar o comando `mkdir` para criar uma pasta com o nome \"temp\". Aqui est√° o comando:\n",
            "\n",
            "```bash\n",
            "mkdir temp\n",
            "``` \n",
            "\n",
            "Este comando ir√° criar uma pasta chamada \"temp\" no diret√≥rio atual.\n",
            "Command 'Claro! Voc√™ pode usar o comando `mkdir` para criar uma pasta com o nome \"temp\". Aqui est√° o comando:\n",
            "\n",
            "```bash\n",
            "mkdir temp\n",
            "``` \n",
            "\n",
            "Este comando ir√° criar uma pasta chamada \"temp\" no diret√≥rio atual.' returned non-zero exit status 127.\n"
          ]
        }
      ],
      "source": [
        "# trecho de c√≥digo para criar uma pasta com o nome temp\n",
        "\n",
        "comando = gerador_comando_shell(\"Crie uma pasta com o nome temp\")\n",
        "print(comando)\n",
        "executar_comando_shell(comando)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn1wbCFU6QUZ",
        "outputId": "0a395a71-b7ab-42d3-908b-9b907828b446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command 'Para apagar a pasta com o nome \"temp\", voc√™ pode usar o comando `rm -r temp`. Este comando ir√° excluir a pasta \"temp\" e todo o seu conte√∫do de forma recursiva. Certifique-se de estar no diret√≥rio correto antes de executar este comando' returned non-zero exit status 127.\n"
          ]
        }
      ],
      "source": [
        "# trecho de c√≥digo para apagar uma pasta com o nome temp\n",
        "\n",
        "comando = gerador_comando_shell('apague a pasta com o nome temp')\n",
        "executar_comando_shell(comando)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkh1jl1R79dE"
      },
      "outputs": [],
      "source": [
        "#@title Gerador de Conjuntos de Dados\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "mensagem_sistema = 'Voc√™ √© um assistente que entende de Ci√™ncia de Dados.'\n",
        "\n",
        "mensagem_usuario = \"\"\"\n",
        "   Crie um pequeno conjunto de dados sobre o total de vendas no √∫ltimo ano.\n",
        "   O formato do conjunto de dados deve ser um dataframe com 12 linhas e 2 colunas.\n",
        "   As colunas devem ser chamadas de \"mes\" e \"total_vendas\".\n",
        "   A coluna \"mes\" deve conter as formas abreviadas dos nomes dos meses de \"Jan\" a \"Dez\".\n",
        "   A coluna \"total_vendas\" deve conter valores num√©ricos aleat√≥rios retirados de um\n",
        "   distribui√ß√£o normal com m√©dia 100000 e desvio padr√£o 5000.\n",
        "   Forne√ßa o c√≥digo Python para gerar o conjunto de dados e, em seguida, forne√ßa a sa√≠da\n",
        "    no formato de uma tabela.\n",
        "\"\"\"\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo\",\n",
        "   messages = [{\"role\": \"system\", \"content\": mensagem_sistema},\n",
        "               {\"role\": \"user\", \"content\": mensagem_usuario}]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIwiGSTg8QWV",
        "outputId": "e3cca7ad-a26d-4914-ad40-e05707f14e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aqui est√° o c√≥digo Python para gerar o conjunto de dados e a sa√≠da em formato de tabela:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "\n",
            "# Criando o conjunto de dados\n",
            "meses = [\"Jan\", \"Fev\", \"Mar\", \"Abr\", \"Mai\", \"Jun\", \"Jul\", \"Ago\", \"Set\", \"Out\", \"Nov\", \"Dez\"]\n",
            "total_vendas = np.random.normal(100000, 5000, 12)\n",
            "\n",
            "data = {\n",
            "    \"mes\": meses,\n",
            "    \"total_vendas\": total_vendas\n",
            "}\n",
            "\n",
            "df = pd.DataFrame(data)\n",
            "\n",
            "# Exibindo o conjunto de dados em formato de tabela\n",
            "print(df)\n",
            "```\n",
            "\n",
            "Sa√≠da do conjunto de dados em formato de tabela:\n",
            "\n",
            "```\n",
            "    mes    total_vendas\n",
            "0   Jan    98866.395641\n",
            "1   Fev   102568.079104\n",
            "2   Mar   101764.780843\n",
            "3   Abr    98436.707181\n",
            "4   Mai    99455.393352\n",
            "5   Jun    99437.501874\n",
            "6   Jul   100009.352908\n",
            "7   Ago    99600.231724\n",
            "8   Set   103634.287184\n",
            "9   Out    99634.066355\n",
            "10  Nov   101345.453846\n",
            "11  Dez    96619.739903\n",
            "``` \n",
            "\n",
            "Este √© um conjunto de dados fict√≠cio e os valores de vendas s√£o gerados aleatoriamente usando uma distribui√ß√£o normal com m√©dia de 100000 e desvio padr√£o de 5000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg5e39wPA3yU",
        "outputId": "c442b0d0-6071-4ba3-e2d0-ba738022af0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    mes   total_vendas\n",
            "0   Jan  107272.920583\n",
            "1   Fev   95710.770321\n",
            "2   Mar   89926.790366\n",
            "3   Abr   97353.753804\n",
            "4   Mai   98580.419847\n",
            "5   Jun   95174.889052\n",
            "6   Jul  100483.774294\n",
            "7   Ago   90394.758696\n",
            "8   Set   97909.761955\n",
            "9   Out  103615.069726\n",
            "10  Nov  103902.347458\n",
            "11  Dez  102186.877579\n"
          ]
        }
      ],
      "source": [
        "#@title Teste do c√≥digo gerado\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Criando o conjunto de dados\n",
        "meses = [\"Jan\", \"Fev\", \"Mar\", \"Abr\", \"Mai\", \"Jun\", \"Jul\", \"Ago\", \"Set\", \"Out\", \"Nov\", \"Dez\"]\n",
        "total_vendas = np.random.normal(100000, 5000, 12)\n",
        "\n",
        "data = {\n",
        "    \"mes\": meses,\n",
        "    \"total_vendas\": total_vendas\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Exibindo o conjunto de dados em formato de tabela\n",
        "print(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbAZtAiNHDSZgnlZeuRssa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}