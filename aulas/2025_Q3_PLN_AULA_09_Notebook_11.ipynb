{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2025.Q3-PLN/blob/main/2025_Q3_PLN_AULA_09_Notebook_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz8ST67pSdeF"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2025-Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDFqzPZFSfBx"
      },
      "source": [
        "## **Introdução à API da OpenAI**\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFIowMuI69Lv",
        "outputId": "827b9349-ad2b-4cfa-90db-ff2f9ff5ebf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "#@title Versão do Python no Google Colab\n",
        "\n",
        "import sys\n",
        "\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwdwRDIwC5Me"
      },
      "source": [
        "## **Configuração da API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjLmc6Yr1a2B",
        "outputId": "2576edf3-b94f-496d-ae8f-a5099cf83871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "#@title Instalando a biblioteca da API da OpenAI\n",
        "\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbFq4KS1fa4T",
        "outputId": "0b31cc2f-dbdc-4a81-b8bf-d6df5a8e2952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.109.1\n"
          ]
        }
      ],
      "source": [
        "#@title Versão da API da OpenAI\n",
        "\n",
        "import openai\n",
        "\n",
        "print(openai.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Definindo a chave da API\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass()\n",
        "\n",
        "#import os\n",
        "\n",
        "#os.environ[\"OPENAI_API_KEY\"] = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InAV3BG2iF5z",
        "outputId": "096c1510-bbb9-4c52-b606-72e6cfa637ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O módulo `getpass` em Python é utilizado para obter senhas e outros tipos de entrada sensível do usuário sem que essas informações sejam exibidas na tela. Isso é útil para aumentar a segurança, evitando que a senha ou a chave da API sejam vistas por pessoas próximas ao usuário."
      ],
      "metadata": {
        "id": "V0YkYyCdif7j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz8DO2GyJdge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5287e7d-35d9-49fb-fc38-b46163b1f94d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response(id='resp_0c01b76ec79b89220068eaa6420b888193935c82947fe8fabb', created_at=1760208450.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_0c01b76ec79b89220068eaa643ce3c8193a8752803bc5086fb', content=[ResponseOutputText(annotations=[], text='Isso é um teste.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=14, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=6, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=20), user=None, billing={'payer': 'developer'}, store=True)\n"
          ]
        }
      ],
      "source": [
        "#@title Primeiro teste\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI(api_key= OPENAI_API_KEY)\n",
        "\n",
        "# Response API\n",
        "resposta = cliente.responses.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  input=\"Diga que isso é um teste\"\n",
        ")\n",
        "\n",
        "print(resposta)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF5XYMZX9MQA",
        "outputId": "3ae8e62a-2a76-403c-c800-88e1bd5fad89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Response(id='resp_0c01b76ec79b89220068eaa6420b888193935c82947fe8fabb', created_at=1760208450.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_0c01b76ec79b89220068eaa643ce3c8193a8752803bc5086fb', content=[ResponseOutputText(annotations=[], text='Isso é um teste.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=14, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=6, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=20), user=None, billing={'payer': 'developer'}, store=True)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.model_dump_json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "9SXubIDL9Q_L",
        "outputId": "086ad25f-d1b5-4be9-a5f4-2fc7341d5c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"id\":\"resp_0c01b76ec79b89220068eaa6420b888193935c82947fe8fabb\",\"created_at\":1760208450.0,\"error\":null,\"incomplete_details\":null,\"instructions\":null,\"metadata\":{},\"model\":\"gpt-4o-mini-2024-07-18\",\"object\":\"response\",\"output\":[{\"id\":\"msg_0c01b76ec79b89220068eaa643ce3c8193a8752803bc5086fb\",\"content\":[{\"annotations\":[],\"text\":\"Isso é um teste.\",\"type\":\"output_text\",\"logprobs\":[]}],\"role\":\"assistant\",\"status\":\"completed\",\"type\":\"message\"}],\"parallel_tool_calls\":true,\"temperature\":1.0,\"tool_choice\":\"auto\",\"tools\":[],\"top_p\":1.0,\"background\":false,\"conversation\":null,\"max_output_tokens\":null,\"max_tool_calls\":null,\"previous_response_id\":null,\"prompt\":null,\"prompt_cache_key\":null,\"reasoning\":{\"effort\":null,\"generate_summary\":null,\"summary\":null},\"safety_identifier\":null,\"service_tier\":\"default\",\"status\":\"completed\",\"text\":{\"format\":{\"type\":\"text\"},\"verbosity\":\"medium\"},\"top_logprobs\":0,\"truncation\":\"disabled\",\"usage\":{\"input_tokens\":14,\"input_tokens_details\":{\"cached_tokens\":0},\"output_tokens\":6,\"output_tokens_details\":{\"reasoning_tokens\":0},\"total_tokens\":20},\"user\":null,\"billing\":{\"payer\":\"developer\"},\"store\":true}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Formatando a resposta\n",
        "\n",
        "import json\n",
        "\n",
        "# Carregar o JSON em um dicionário Python\n",
        "dados = json.loads(resposta.model_dump_json())\n",
        "\n",
        "# Converter o dicionário em uma string JSON formatada com indentação\n",
        "json_formatado = json.dumps(dados, indent=4, ensure_ascii=False)\n",
        "\n",
        "# Dividir a string JSON formatada em linhas individuais\n",
        "linhas = json_formatado.splitlines()\n",
        "\n",
        "# Exibir cada linha separadamente\n",
        "for linha in linhas:\n",
        "    print(linha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nPU9VuSA4Kc",
        "outputId": "65e04e07-9a8e-44af-eadb-774643af8709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"id\": \"resp_0c01b76ec79b89220068eaa6420b888193935c82947fe8fabb\",\n",
            "    \"created_at\": 1760208450.0,\n",
            "    \"error\": null,\n",
            "    \"incomplete_details\": null,\n",
            "    \"instructions\": null,\n",
            "    \"metadata\": {},\n",
            "    \"model\": \"gpt-4o-mini-2024-07-18\",\n",
            "    \"object\": \"response\",\n",
            "    \"output\": [\n",
            "        {\n",
            "            \"id\": \"msg_0c01b76ec79b89220068eaa643ce3c8193a8752803bc5086fb\",\n",
            "            \"content\": [\n",
            "                {\n",
            "                    \"annotations\": [],\n",
            "                    \"text\": \"Isso é um teste.\",\n",
            "                    \"type\": \"output_text\",\n",
            "                    \"logprobs\": []\n",
            "                }\n",
            "            ],\n",
            "            \"role\": \"assistant\",\n",
            "            \"status\": \"completed\",\n",
            "            \"type\": \"message\"\n",
            "        }\n",
            "    ],\n",
            "    \"parallel_tool_calls\": true,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tool_choice\": \"auto\",\n",
            "    \"tools\": [],\n",
            "    \"top_p\": 1.0,\n",
            "    \"background\": false,\n",
            "    \"conversation\": null,\n",
            "    \"max_output_tokens\": null,\n",
            "    \"max_tool_calls\": null,\n",
            "    \"previous_response_id\": null,\n",
            "    \"prompt\": null,\n",
            "    \"prompt_cache_key\": null,\n",
            "    \"reasoning\": {\n",
            "        \"effort\": null,\n",
            "        \"generate_summary\": null,\n",
            "        \"summary\": null\n",
            "    },\n",
            "    \"safety_identifier\": null,\n",
            "    \"service_tier\": \"default\",\n",
            "    \"status\": \"completed\",\n",
            "    \"text\": {\n",
            "        \"format\": {\n",
            "            \"type\": \"text\"\n",
            "        },\n",
            "        \"verbosity\": \"medium\"\n",
            "    },\n",
            "    \"top_logprobs\": 0,\n",
            "    \"truncation\": \"disabled\",\n",
            "    \"usage\": {\n",
            "        \"input_tokens\": 14,\n",
            "        \"input_tokens_details\": {\n",
            "            \"cached_tokens\": 0\n",
            "        },\n",
            "        \"output_tokens\": 6,\n",
            "        \"output_tokens_details\": {\n",
            "            \"reasoning_tokens\": 0\n",
            "        },\n",
            "        \"total_tokens\": 20\n",
            "    },\n",
            "    \"user\": null,\n",
            "    \"billing\": {\n",
            "        \"payer\": \"developer\"\n",
            "    },\n",
            "    \"store\": true\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(resposta.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQeIbxw2Cqj0",
        "outputId": "b7ecd27d-90f9-4eb7-a800-404e6b2a3f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isso é um teste.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Lista de Modelos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "# obter a lista de modelos\n",
        "modelos = cliente.models.list()"
      ],
      "metadata": {
        "id": "xjBBIDFowqFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imprimir total de modelos\n",
        "print(len(modelos.data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho-tNOdQxCpQ",
        "outputId": "ab801b85-522b-44f4-8efb-65a252cc4a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imprimir os nomes dos modelos\n",
        "for modelo in modelos.data:\n",
        "   print(modelo.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LwybwgoxWmK",
        "outputId": "8010cc6b-8f33-4e12-bf8d-bcfb13d6c997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-4-0613\n",
            "gpt-4\n",
            "gpt-3.5-turbo\n",
            "sora-2-pro\n",
            "gpt-audio-mini-2025-10-06\n",
            "gpt-realtime-mini\n",
            "gpt-realtime-mini-2025-10-06\n",
            "sora-2\n",
            "davinci-002\n",
            "babbage-002\n",
            "gpt-3.5-turbo-instruct\n",
            "gpt-3.5-turbo-instruct-0914\n",
            "dall-e-3\n",
            "dall-e-2\n",
            "gpt-4-1106-preview\n",
            "gpt-3.5-turbo-1106\n",
            "tts-1-hd\n",
            "tts-1-1106\n",
            "tts-1-hd-1106\n",
            "text-embedding-3-small\n",
            "text-embedding-3-large\n",
            "gpt-4-0125-preview\n",
            "gpt-4-turbo-preview\n",
            "gpt-3.5-turbo-0125\n",
            "gpt-4-turbo\n",
            "gpt-4-turbo-2024-04-09\n",
            "gpt-4o\n",
            "gpt-4o-2024-05-13\n",
            "gpt-4o-mini-2024-07-18\n",
            "gpt-4o-mini\n",
            "gpt-4o-2024-08-06\n",
            "chatgpt-4o-latest\n",
            "o1-mini-2024-09-12\n",
            "o1-mini\n",
            "gpt-4o-realtime-preview-2024-10-01\n",
            "gpt-4o-audio-preview-2024-10-01\n",
            "gpt-4o-audio-preview\n",
            "gpt-4o-realtime-preview\n",
            "omni-moderation-latest\n",
            "omni-moderation-2024-09-26\n",
            "gpt-4o-realtime-preview-2024-12-17\n",
            "gpt-4o-audio-preview-2024-12-17\n",
            "gpt-4o-mini-realtime-preview-2024-12-17\n",
            "gpt-4o-mini-audio-preview-2024-12-17\n",
            "o1-2024-12-17\n",
            "o1\n",
            "gpt-4o-mini-realtime-preview\n",
            "gpt-4o-mini-audio-preview\n",
            "o3-mini\n",
            "o3-mini-2025-01-31\n",
            "gpt-4o-2024-11-20\n",
            "gpt-4o-search-preview-2025-03-11\n",
            "gpt-4o-search-preview\n",
            "gpt-4o-mini-search-preview-2025-03-11\n",
            "gpt-4o-mini-search-preview\n",
            "gpt-4o-transcribe\n",
            "gpt-4o-mini-transcribe\n",
            "o1-pro-2025-03-19\n",
            "o1-pro\n",
            "gpt-4o-mini-tts\n",
            "o3-2025-04-16\n",
            "o4-mini-2025-04-16\n",
            "o3\n",
            "o4-mini\n",
            "gpt-4.1-2025-04-14\n",
            "gpt-4.1\n",
            "gpt-4.1-mini-2025-04-14\n",
            "gpt-4.1-mini\n",
            "gpt-4.1-nano-2025-04-14\n",
            "gpt-4.1-nano\n",
            "gpt-image-1\n",
            "codex-mini-latest\n",
            "gpt-4o-realtime-preview-2025-06-03\n",
            "gpt-4o-audio-preview-2025-06-03\n",
            "o4-mini-deep-research\n",
            "o4-mini-deep-research-2025-06-26\n",
            "gpt-5-chat-latest\n",
            "gpt-5-2025-08-07\n",
            "gpt-5\n",
            "gpt-5-mini-2025-08-07\n",
            "gpt-5-mini\n",
            "gpt-5-nano-2025-08-07\n",
            "gpt-5-nano\n",
            "gpt-audio-2025-08-28\n",
            "gpt-realtime\n",
            "gpt-realtime-2025-08-28\n",
            "gpt-audio\n",
            "gpt-5-codex\n",
            "gpt-image-1-mini\n",
            "gpt-5-pro-2025-10-06\n",
            "gpt-5-pro\n",
            "gpt-audio-mini\n",
            "gpt-3.5-turbo-16k\n",
            "tts-1\n",
            "whisper-1\n",
            "text-embedding-ada-002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Função para verificar se um modelo existe\n",
        "\n",
        "def verificar_modelo(nome_modelo):\n",
        "   modelos = cliente.models.list()\n",
        "   for modelo in modelos.data:\n",
        "      if modelo.id == nome_modelo:\n",
        "         return True\n",
        "   return False"
      ],
      "metadata": {
        "id": "q2qeGjE5xebY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(verificar_modelo(\"gpt-5\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61fQ69lrxqXo",
        "outputId": "90b86483-a10a-4763-82d3-9911282668ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Função para verificar se parte do nome está na lista de modelos\n",
        "\n",
        "def verificar_modelos_parcial(parte_nome):\n",
        "   modelos = cliente.models.list()\n",
        "   nomes_modelos = [modelo.id for modelo in modelos.data]\n",
        "   modelos_identificados = [modelo for modelo in nomes_modelos if parte_nome.lower() in modelo.lower()]\n",
        "\n",
        "   return modelos_identificados"
      ],
      "metadata": {
        "id": "wVxNyS6BxtHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verificar_modelos_parcial(\"gpt-5\")"
      ],
      "metadata": {
        "id": "A9E1OrbLx5zC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eee70ed-8652-47ce-83c4-6d203ae2ab3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gpt-5-chat-latest',\n",
              " 'gpt-5-2025-08-07',\n",
              " 'gpt-5',\n",
              " 'gpt-5-mini-2025-08-07',\n",
              " 'gpt-5-mini',\n",
              " 'gpt-5-nano-2025-08-07',\n",
              " 'gpt-5-nano',\n",
              " 'gpt-5-codex',\n",
              " 'gpt-5-pro-2025-10-06',\n",
              " 'gpt-5-pro']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRZI4tjTM3o3"
      },
      "source": [
        "**Requisições HTTP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc9HteJ7MdB5",
        "outputId": "829fa53a-f3b2-4246-c309-24f31c5ab751"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'chatcmpl-CPYz9YJcVt7vETHeq7jYieXuTwtor',\n",
              " 'object': 'chat.completion',\n",
              " 'created': 1760208719,\n",
              " 'model': 'gpt-4.1-mini-2025-04-14',\n",
              " 'choices': [{'index': 0,\n",
              "   'message': {'role': 'assistant',\n",
              "    'content': 'Positivo',\n",
              "    'refusal': None,\n",
              "    'annotations': []},\n",
              "   'logprobs': None,\n",
              "   'finish_reason': 'stop'}],\n",
              " 'usage': {'prompt_tokens': 59,\n",
              "  'completion_tokens': 2,\n",
              "  'total_tokens': 61,\n",
              "  'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
              "  'completion_tokens_details': {'reasoning_tokens': 0,\n",
              "   'audio_tokens': 0,\n",
              "   'accepted_prediction_tokens': 0,\n",
              "   'rejected_prediction_tokens': 0}},\n",
              " 'service_tier': 'default',\n",
              " 'system_fingerprint': 'fp_c064fdde7c'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#@title Endpoint *Chat Completions* (Análise de Sentimentos)\n",
        "\n",
        "import requests\n",
        "\n",
        "endpoint = \"https://api.openai.com/v1/chat/completions\"\n",
        "\n",
        "mensagem_sistema = 'Você é um assistente que analisa sentimentos de avaliações de produtos'\n",
        "mensagem_usuario = \"Aqui está uma avaliação de um produto: 'Este produto é incrível!\"\n",
        "mensagem_assistente = \"Classifique o sentimento retornando apenas 'Positivo' ou 'Negativo'. \"\n",
        "\n",
        "parametros = {\n",
        "   \"model\": \"gpt-4.1-mini\",\n",
        "   \"messages\": [\n",
        "      {\"role\": \"system\", \"content\": mensagem_sistema},\n",
        "      {\"role\": \"user\", \"content\": mensagem_usuario},\n",
        "      {\"role\": \"assistant\", \"content\": mensagem_assistente}]\n",
        "}\n",
        "headers = {\n",
        "   \"Content-Type\": \"application/json\",\n",
        "   \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
        "}\n",
        "\n",
        "resposta = requests.post(endpoint, json=parametros, headers=headers)\n",
        "resposta.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x18QiMbUZbI4",
        "outputId": "4dff38be-0e92-44a2-8205-7bad34ca7808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positivo\n"
          ]
        }
      ],
      "source": [
        "# imprimir apenas resposta do assistente\n",
        "print(resposta.json()[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCAM03rvnW1B"
      },
      "source": [
        "**Utilizando a biblioteca da *API***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title *Chat Completions*\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "  model=\"gpt-4.1-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": \"Qual a capital do Brasil? Retorne apenas o nome\"}\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "xke_3x5XF6GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resposta.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkuSw_OpHNhE",
        "outputId": "075bb1f0-70a7-4d14-c457-a1b6f8486cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brasília\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMXjHddkfiEW"
      },
      "outputs": [],
      "source": [
        "#@title *Chat Completions* (Correção Gramatical)\n",
        "\n",
        "mensagem_sistema = 'Você receberá instruções e sua tarefa é corrigir para o Português'\n",
        "mensagem_usuario = \"o mecado estava fexado.\"\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-4.1-mini\",\n",
        "   messages = [{\"role\": \"system\", \"content\": mensagem_sistema},\n",
        "               {\"role\": \"user\", \"content\": mensagem_usuario}]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ4OKXgAf5rG",
        "outputId": "181fedc7-f8cb-4c32-e603-b1ab23491f45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-CPZ09rZl5z1ErkkRRCkSO4rCndmSK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='O mercado estava fechado.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760208781, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_c064fdde7c', usage=CompletionUsage(completion_tokens=5, prompt_tokens=33, total_tokens=38, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "resposta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(resposta.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1D6itRZI5oa",
        "outputId": "a84fbac7-3c9c-44cd-b65a-078eef72bef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O mercado estava fechado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jci5ArpagGG7",
        "outputId": "1f7dd86a-e19d-4a30-b7bb-8ad8508d101a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chatcmpl-CPZ09rZl5z1ErkkRRCkSO4rCndmSK\n"
          ]
        }
      ],
      "source": [
        "# id\n",
        "print(resposta.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8bP8g1xgGG-",
        "outputId": "ae6d57fa-b0b4-4d25-b401-3b155aa7f108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-4.1-mini-2025-04-14\n"
          ]
        }
      ],
      "source": [
        "# modelo\n",
        "print(resposta.model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubcuMEWxgGG_",
        "outputId": "cd4f5649-2e56-4971-d53d-0ffbe0492177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38\n"
          ]
        }
      ],
      "source": [
        "# total de tokens\n",
        "print(resposta.usage.total_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Referências**:\n",
        "\n",
        "https://github.com/openai/openai-python\n",
        "\n",
        "https://platform.openai.com/docs/api-reference"
      ],
      "metadata": {
        "id": "nKBKOZ-QDNG-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfJBmpAkbTyu55ZGE1bIn/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}